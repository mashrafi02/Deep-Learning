{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[['age', 'affordibility']], df['bought_insurance'], test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)\n",
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myPNN():\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2  =1\n",
    "        self.bias = 0\n",
    "    \n",
    "    def fit(self, x, y, epochs, loss_thresold):\n",
    "        self.w1, self.w2, self.bias = self.gradient_decent(x[:,0], x[:,1], np.array(y), epochs, loss_thresold)\n",
    "\n",
    "    def sigmoid_numpy(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def log_loss(self, ytrue, ypredicted):\n",
    "        epsilon = 1e-15\n",
    "        y_predicted_new = [max(i, epsilon) for i in ypredicted]\n",
    "        y_predicted_new = [min(i,(1-epsilon)) for i in y_predicted_new]\n",
    "        y_predicted_new = np.array(y_predicted_new)\n",
    "        return -np.mean(ytrue*np.log(y_predicted_new) + (1-ytrue)*np.log(1-y_predicted_new))\n",
    "\n",
    "    def gradient_decent(self, age, affordibility, y_true, epochs, loss_thresold):\n",
    "        w1 = w2 = 1\n",
    "        bias = 0\n",
    "        l_rate = 0.5\n",
    "        n = len(age)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            w_sum = w1*age + w2*affordibility + bias \n",
    "            y_predicted = self.sigmoid_numpy(w_sum)\n",
    "\n",
    "            loss = self.log_loss(y_true, y_predicted)\n",
    "\n",
    "            w1d = (1/n)*np.dot(np.transpose(age), (y_predicted-y_true))\n",
    "            w2d = (1/n)*np.dot(np.transpose(affordibility), (y_predicted-y_true))\n",
    "\n",
    "            bias_d = np.mean(y_predicted - y_true)\n",
    "\n",
    "            w1 = w1 - l_rate*w1d\n",
    "            w2 = w2 - l_rate*w2d\n",
    "\n",
    "            bias = bias - l_rate*bias_d\n",
    "\n",
    "            if i%50 == 0:\n",
    "                print(f\"epoch: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}\")\n",
    "\n",
    "            if loss<=loss_thresold:\n",
    "                print(f\"epoch: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}\")\n",
    "                break\n",
    "    \n",
    "        return w1, w2, bias\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        weight_sum = self.w1 * x_test[:,0] + self.w2 * x_test[:,1] + self.bias\n",
    "        return self.sigmoid_numpy(weight_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, w1: 0.9731486632854714, w2: 0.9193778047177081, bias: -0.15672038455899562, loss: 0.7658801441735696\n",
      "epoch: 50, w1: 2.0402261107325423, w2: 0.7656807197984448, bias: -1.684440661940269, loss: 0.4678777038525041\n",
      "epoch: 100, w1: 2.8536179181591845, w2: 0.9369089747618125, bias: -2.2434118517680512, loss: 0.42648439251357984\n",
      "epoch: 150, w1: 3.3806659790772553, w2: 1.0641665522420274, bias: -2.624655355760178, loss: 0.4085023575019875\n",
      "epoch: 200, w1: 3.7453157366533683, w2: 1.164161923462531, bias: -2.9010582920951413, loss: 0.3995649653504054\n",
      "epoch: 225, w1: 3.8874404071812148, w2: 1.2063670702033003, bias: -3.012083365395807, loss: 0.39679107150065906\n"
     ]
    }
   ],
   "source": [
    "custom_model = myPNN()\n",
    "custom_model.fit(x_train, y_train, epochs = 500, loss_thresold = 0.3968)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68058474, 0.53444633, 0.71771638, 0.84919746, 0.82514739,\n",
       "       0.28450839])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([0.687469, 0.53711617, 0.72532845, 0.85733855, 0.8334979, 0.2793526])\n",
    "this was the actual prediction by tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
