{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RowNumber  CustomerId    Surname  CreditScore Geography  Gender   Age  \\\n",
       "0              1    15634602   Hargrave          619    France  Female  42.0   \n",
       "1              2    15647311       Hill          608     Spain  Female  41.0   \n",
       "2              3    15619304       Onio          502    France  Female  42.0   \n",
       "3              4    15701354       Boni          699    France  Female  39.0   \n",
       "4              5    15737888   Mitchell          850     Spain  Female  43.0   \n",
       "...          ...         ...        ...          ...       ...     ...   ...   \n",
       "9997        9998    15584532        Liu          709    France  Female  36.0   \n",
       "9998        9999    15682355  Sabbatini          772   Germany    Male  42.0   \n",
       "9999        9999    15682355  Sabbatini          772   Germany    Male  42.0   \n",
       "10000      10000    15628319     Walker          792    France  Female  28.0   \n",
       "10001      10000    15628319     Walker          792    France  Female  28.0   \n",
       "\n",
       "       Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0           2       0.00              1        1.0             1.0   \n",
       "1           1   83807.86              1        0.0             1.0   \n",
       "2           8  159660.80              3        1.0             0.0   \n",
       "3           1       0.00              2        0.0             0.0   \n",
       "4           2  125510.82              1        NaN             1.0   \n",
       "...       ...        ...            ...        ...             ...   \n",
       "9997        7       0.00              1        0.0             1.0   \n",
       "9998        3   75075.31              2        1.0             0.0   \n",
       "9999        3   75075.31              2        1.0             0.0   \n",
       "10000       4  130142.79              1        1.0             0.0   \n",
       "10001       4  130142.79              1        1.0             0.0   \n",
       "\n",
       "       EstimatedSalary  Exited  \n",
       "0            101348.88       1  \n",
       "1            112542.58       0  \n",
       "2            113931.57       1  \n",
       "3             93826.63       0  \n",
       "4             79084.10       0  \n",
       "...                ...     ...  \n",
       "9997          42085.58       1  \n",
       "9998          92888.52       1  \n",
       "9999          92888.52       1  \n",
       "10000         38190.78       0  \n",
       "10001         38190.78       0  \n",
       "\n",
       "[10002 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          1\n",
       "Gender             0\n",
       "Age                1\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          1\n",
       "IsActiveMember     1\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                float64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard          float64\n",
       "IsActiveMember     float64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['RowNumber','CustomerId','Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9998 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CreditScore Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
       "0              619    France  Female  42.0       2       0.00              1   \n",
       "1              608     Spain  Female  41.0       1   83807.86              1   \n",
       "2              502    France  Female  42.0       8  159660.80              3   \n",
       "3              699    France  Female  39.0       1       0.00              2   \n",
       "5              645     Spain    Male  44.0       8  113755.78              2   \n",
       "...            ...       ...     ...   ...     ...        ...            ...   \n",
       "9997           709    France  Female  36.0       7       0.00              1   \n",
       "9998           772   Germany    Male  42.0       3   75075.31              2   \n",
       "9999           772   Germany    Male  42.0       3   75075.31              2   \n",
       "10000          792    France  Female  28.0       4  130142.79              1   \n",
       "10001          792    France  Female  28.0       4  130142.79              1   \n",
       "\n",
       "       HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0            1.0             1.0        101348.88       1  \n",
       "1            0.0             1.0        112542.58       0  \n",
       "2            1.0             0.0        113931.57       1  \n",
       "3            0.0             0.0         93826.63       0  \n",
       "5            1.0             0.0        149756.71       1  \n",
       "...          ...             ...              ...     ...  \n",
       "9997         0.0             1.0         42085.58       1  \n",
       "9998         1.0             0.0         92888.52       1  \n",
       "9999         1.0             0.0         92888.52       1  \n",
       "10000        1.0             0.0         38190.78       0  \n",
       "10001        1.0             0.0         38190.78       0  \n",
       "\n",
       "[9998 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in df1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Geography',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Exited']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 645 376 528 497 476 549 635 616 653 587 726 732 636 510\n",
      " 669 846 577 756 571 574 411 591 533 553 520 722 475 490 804 850 582 472\n",
      " 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725 511 614 742\n",
      " 687 555 684 603 751 581 735 661 675 738 813 657 604 519 664 678 757 416\n",
      " 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773 814 710\n",
      " 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625 432 770\n",
      " 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535 716 539\n",
      " 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778 514 525\n",
      " 715 580 807 501 521 759 516 711 618 643 671 689 620 676 572 695 592 567\n",
      " 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771 681\n",
      " 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799 602\n",
      " 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644 626\n",
      " 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593 801\n",
      " 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724 548\n",
      " 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798 641\n",
      " 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598 741\n",
      " 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427 839\n",
      " 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844 450\n",
      " 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456 435\n",
      " 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812 677\n",
      " 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837 794\n",
      " 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449 440\n",
      " 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836 473\n",
      " 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422 825\n",
      " 430 436 426 408 847 418 437 410 454 822 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n",
      "Age : [42.   41.   39.   44.   29.   31.   24.   34.   25.   35.   45.   58.\n",
      " 45.25 32.34 38.   46.   36.44 43.   36.   33.   40.   51.   61.   49.\n",
      " 32.   27.   37.   19.   66.   56.   26.   21.   55.   75.   22.   30.\n",
      " 28.   65.   48.   52.   50.   57.   73.   47.   54.   72.   20.   67.\n",
      " 79.   62.   53.   80.   59.   68.   23.   60.   70.   63.   64.   18.\n",
      " 82.   69.   74.   71.   76.   77.   88.   85.   84.   78.   81.   92.\n",
      " 83.  ]\n",
      "Tenure : [ 2  1  8  4  6  3 10  5  7  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1. 0.]\n",
      "IsActiveMember : [1. 0.]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    print(f\"{i} : {df1[i].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Gender'] = df1['Gender'].replace({'Female':0,'Male':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df1,pd.get_dummies(df1['Geography']).astype('float')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9998 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CreditScore Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
       "0              619    France       0  42.0       2       0.00              1   \n",
       "1              608     Spain       0  41.0       1   83807.86              1   \n",
       "2              502    France       0  42.0       8  159660.80              3   \n",
       "3              699    France       0  39.0       1       0.00              2   \n",
       "5              645     Spain       1  44.0       8  113755.78              2   \n",
       "...            ...       ...     ...   ...     ...        ...            ...   \n",
       "9997           709    France       0  36.0       7       0.00              1   \n",
       "9998           772   Germany       1  42.0       3   75075.31              2   \n",
       "9999           772   Germany       1  42.0       3   75075.31              2   \n",
       "10000          792    France       0  28.0       4  130142.79              1   \n",
       "10001          792    France       0  28.0       4  130142.79              1   \n",
       "\n",
       "       HasCrCard  IsActiveMember  EstimatedSalary  Exited  France  Germany  \\\n",
       "0            1.0             1.0        101348.88       1     1.0      0.0   \n",
       "1            0.0             1.0        112542.58       0     0.0      0.0   \n",
       "2            1.0             0.0        113931.57       1     1.0      0.0   \n",
       "3            0.0             0.0         93826.63       0     1.0      0.0   \n",
       "5            1.0             0.0        149756.71       1     0.0      0.0   \n",
       "...          ...             ...              ...     ...     ...      ...   \n",
       "9997         0.0             1.0         42085.58       1     1.0      0.0   \n",
       "9998         1.0             0.0         92888.52       1     0.0      1.0   \n",
       "9999         1.0             0.0         92888.52       1     0.0      1.0   \n",
       "10000        1.0             0.0         38190.78       0     1.0      0.0   \n",
       "10001        1.0             0.0         38190.78       0     1.0      0.0   \n",
       "\n",
       "       Spain  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "5        1.0  \n",
       "...      ...  \n",
       "9997     0.0  \n",
       "9998     0.0  \n",
       "9999     0.0  \n",
       "10000    0.0  \n",
       "10001    0.0  \n",
       "\n",
       "[9998 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('Geography', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 645 376 528 497 476 549 635 616 653 587 726 732 636 510\n",
      " 669 846 577 756 571 574 411 591 533 553 520 722 475 490 804 850 582 472\n",
      " 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725 511 614 742\n",
      " 687 555 684 603 751 581 735 661 675 738 813 657 604 519 664 678 757 416\n",
      " 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773 814 710\n",
      " 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625 432 770\n",
      " 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535 716 539\n",
      " 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778 514 525\n",
      " 715 580 807 501 521 759 516 711 618 643 671 689 620 676 572 695 592 567\n",
      " 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771 681\n",
      " 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799 602\n",
      " 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644 626\n",
      " 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593 801\n",
      " 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724 548\n",
      " 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798 641\n",
      " 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598 741\n",
      " 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427 839\n",
      " 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844 450\n",
      " 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456 435\n",
      " 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812 677\n",
      " 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837 794\n",
      " 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449 440\n",
      " 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836 473\n",
      " 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422 825\n",
      " 430 436 426 408 847 418 437 410 454 822 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Gender : [0 1]\n",
      "Age : [42.   41.   39.   44.   29.   31.   24.   34.   25.   35.   45.   58.\n",
      " 45.25 32.34 38.   46.   36.44 43.   36.   33.   40.   51.   61.   49.\n",
      " 32.   27.   37.   19.   66.   56.   26.   21.   55.   75.   22.   30.\n",
      " 28.   65.   48.   52.   50.   57.   73.   47.   54.   72.   20.   67.\n",
      " 79.   62.   53.   80.   59.   68.   23.   60.   70.   63.   64.   18.\n",
      " 82.   69.   74.   71.   76.   77.   88.   85.   84.   78.   81.   92.\n",
      " 83.  ]\n",
      "Tenure : [ 2  1  8  4  6  3 10  5  7  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1. 0.]\n",
      "IsActiveMember : [1. 0.]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n",
      "France : [1. 0.]\n",
      "Germany : [0. 1.]\n",
      "Spain : [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "columns = [i for i in df2.columns]\n",
    "for i in columns:\n",
    "    print(f\"{i} : {df2[i].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', 'France',\n",
       "       'Germany', 'Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "df2[columns_to_scale] = scale.fit_transform(df2[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.453394</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9998 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0            0.538       0  0.324324     0.2  0.000000       0.000000   \n",
       "1            0.516       0  0.310811     0.1  0.334031       0.000000   \n",
       "2            0.304       0  0.324324     0.8  0.636357       0.666667   \n",
       "3            0.698       0  0.283784     0.1  0.000000       0.333333   \n",
       "5            0.590       1  0.351351     0.8  0.453394       0.333333   \n",
       "...            ...     ...       ...     ...       ...            ...   \n",
       "9997         0.718       0  0.243243     0.7  0.000000       0.000000   \n",
       "9998         0.844       1  0.324324     0.3  0.299226       0.333333   \n",
       "9999         0.844       1  0.324324     0.3  0.299226       0.333333   \n",
       "10000        0.884       0  0.135135     0.4  0.518708       0.000000   \n",
       "10001        0.884       0  0.135135     0.4  0.518708       0.000000   \n",
       "\n",
       "       HasCrCard  IsActiveMember  EstimatedSalary  Exited  France  Germany  \\\n",
       "0            1.0             1.0         0.506735       1     1.0      0.0   \n",
       "1            0.0             1.0         0.562709       0     0.0      0.0   \n",
       "2            1.0             0.0         0.569654       1     1.0      0.0   \n",
       "3            0.0             0.0         0.469120       0     1.0      0.0   \n",
       "5            1.0             0.0         0.748797       1     0.0      0.0   \n",
       "...          ...             ...              ...     ...     ...      ...   \n",
       "9997         0.0             1.0         0.210390       1     1.0      0.0   \n",
       "9998         1.0             0.0         0.464429       1     0.0      1.0   \n",
       "9999         1.0             0.0         0.464429       1     0.0      1.0   \n",
       "10000        1.0             0.0         0.190914       0     1.0      0.0   \n",
       "10001        1.0             0.0         0.190914       0     1.0      0.0   \n",
       "\n",
       "       Spain  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "5        1.0  \n",
       "...      ...  \n",
       "9997     0.0  \n",
       "9998     0.0  \n",
       "9999     0.0  \n",
       "10000    0.0  \n",
       "10001    0.0  \n",
       "\n",
       "[9998 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df2.drop('Exited', axis=1), df2['Exited'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.4950 - accuracy: 0.7869\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4148 - accuracy: 0.8233\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8473\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8486\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8525\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8532\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8570\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8573\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8625\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8616\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8628\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8660\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8647\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8628\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8633\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8672\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8668\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8686\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8657\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8673\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8670\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8668\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8665\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8697\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8692\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8703\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8705\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8723\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8735\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8725\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8738\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8718\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8768\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8741\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.8747\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8743\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8756\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8742\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8746\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8753\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8781\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8758\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8778\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8797\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8796\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8795\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8775\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8808\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8790\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8792\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8802\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.8807\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8802\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8803\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8840\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8842\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8855\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8836\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8841\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.8857\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8846\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8895\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.8885\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8878\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.8886\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2775 - accuracy: 0.8876\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2724 - accuracy: 0.8863\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8892\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8860\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8906\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8905\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8886\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8901\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8903\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8905\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8925\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8930\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.8938\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.8926\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2584 - accuracy: 0.8978\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.8960\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.8941\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.8965\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.8956\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.8925\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.8975\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8960\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2494 - accuracy: 0.8990\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.8963\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.8996\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.8980\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9032\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.8996\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8997\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9010\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9036\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9009\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1bc3d489c40>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape = (12,), activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model.fit(x_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.469642698764801, 0.8495000004768372]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "ypredicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05647841],\n",
       "       [0.3408326 ],\n",
       "       [0.04606973],\n",
       "       ...,\n",
       "       [0.01638244],\n",
       "       [0.10281868],\n",
       "       [0.05431805]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5895    0\n",
       "902     0\n",
       "6152    0\n",
       "5329    0\n",
       "7982    0\n",
       "4619    1\n",
       "4256    0\n",
       "6454    0\n",
       "2673    0\n",
       "9529    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "for element in ypredicted:\n",
    "    if element > 0.5:\n",
    "        ypred.append(1)\n",
    "    else:\n",
    "        ypred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1582\n",
      "           1       0.71      0.48      0.57       418\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.79      0.71      0.74      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1500,   82],\n",
       "       [ 219,  199]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1500,   82],\n",
       "       [ 219,  199]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtf = tf.math.confusion_matrix(y_test, ypred)\n",
    "cmtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1907974672208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974673936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974673360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907944754064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974674128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974674704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974674512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974675280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974672784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1907974675856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31248"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14432"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_quant_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 12)                3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 100)               1305      \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 50)                5055      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_2 (QuantizeWra  (None, 12)                617       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_3 (QuantizeWra  (None, 10)                135       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_4 (QuantizeWra  (None, 1)                 16        \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7131 (27.86 KB)\n",
      "Trainable params: 7103 (27.75 KB)\n",
      "Non-trainable params: 28 (112.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "q_aware_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 4s 3ms/step - loss: 0.2436 - accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1bc43348860>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.fit(x_train,y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpq3xgpt48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpq3xgpt48\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_quantized_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
